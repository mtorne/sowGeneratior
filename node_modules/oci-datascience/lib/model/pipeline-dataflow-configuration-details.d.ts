/**
 * Data Science API
 * Use the Data Science API to organize your data science work, access data and computing resources, and build, train, deploy and manage models and model deployments. For more information, see [Data Science](https://docs.oracle.com/iaas/data-science/using/data-science.htm).

 * OpenAPI spec version: 20190101
 *
 *
 * NOTE: This class is auto generated by OracleSDKGenerator.
 * Do not edit the class manually.
 *
 * Copyright (c) 2020, 2025, Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */
import * as model from "../model";
/**
 * The configuration details of a Dataflow step.
 */
export interface PipelineDataflowConfigurationDetails {
    /**
     * The Spark configuration passed to the running process.
     */
    "configuration"?: any;
    /**
     * The VM shape for the driver.
     */
    "driverShape"?: string;
    "driverShapeConfigDetails"?: model.PipelineShapeConfigDetails;
    /**
     * The VM shape for the executors.
     */
    "executorShape"?: string;
    "executorShapeConfigDetails"?: model.PipelineShapeConfigDetails;
    /**
     * The number of executor VMs requested. Note: Numbers greater than Number.MAX_SAFE_INTEGER will result in rounding issues.
     */
    "numExecutors"?: number;
    /**
     * An Oracle Cloud Infrastructure URI of the bucket to be used as default warehouse directory for BATCH SQL runs.
     */
    "warehouseBucketUri"?: string;
    /**
     * An Oracle Cloud Infrastructure URI of the bucket where the Spark job logs are to be uploaded.
     */
    "logsBucketUri"?: string;
}
export declare namespace PipelineDataflowConfigurationDetails {
    function getJsonObj(obj: PipelineDataflowConfigurationDetails): object;
    function getDeserializedJsonObj(obj: PipelineDataflowConfigurationDetails): object;
}
