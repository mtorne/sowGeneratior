/**
 * Generative AI Service Inference API
 * OCI Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases for text generation, summarization, and text embeddings.

Use the Generative AI service inference API to access your custom model endpoints, or to try the out-of-the-box models to {@link #eNGenerative-ai-inferenceLatestChatResultChat(ENGenerative-ai-inferenceLatestChatResultChatRequest) eNGenerative-ai-inferenceLatestChatResultChat}, {@link #eNGenerative-ai-inferenceLatestGenerateTextResultGenerateText(ENGenerative-ai-inferenceLatestGenerateTextResultGenerateTextRequest) eNGenerative-ai-inferenceLatestGenerateTextResultGenerateText}, {@link #eNGenerative-ai-inferenceLatestSummarizeTextResultSummarizeText(ENGenerative-ai-inferenceLatestSummarizeTextResultSummarizeTextRequest) eNGenerative-ai-inferenceLatestSummarizeTextResultSummarizeText}, and {@link #eNGenerative-ai-inferenceLatestEmbedTextResultEmbedText(ENGenerative-ai-inferenceLatestEmbedTextResultEmbedTextRequest) eNGenerative-ai-inferenceLatestEmbedTextResultEmbedText}.

To use a Generative AI custom model for inference, you must first create an endpoint for that model. Use the {@link #eNGenerative-aiLatest(ENGenerative-aiLatestRequest) eNGenerative-aiLatest} to {@link #eNGenerative-aiLatestModel(ENGenerative-aiLatestModelRequest) eNGenerative-aiLatestModel} by fine-tuning an out-of-the-box model, or a previous version of a custom model, using your own data. Fine-tune the custom model on a {@link #eNGenerative-aiLatestDedicatedAiCluster(ENGenerative-aiLatestDedicatedAiClusterRequest) eNGenerative-aiLatestDedicatedAiCluster}. Then, create a {@link #eNGenerative-aiLatestDedicatedAiCluster(ENGenerative-aiLatestDedicatedAiClusterRequest) eNGenerative-aiLatestDedicatedAiCluster} with an {@link Endpoint} to host your custom model. For resource management in the Generative AI service, use the {@link #eNGenerative-aiLatest(ENGenerative-aiLatestRequest) eNGenerative-aiLatest}.

To learn more about the service, see the [Generative AI documentation](https://docs.oracle.com/iaas/Content/generative-ai/home.htm).

 * OpenAPI spec version: 20231130
 *
 *
 * NOTE: This class is auto generated by OracleSDKGenerator.
 * Do not edit the class manually.
 *
 * Copyright (c) 2020, 2025, Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */
import common = require("oci-common");
import * as requests from "./request";
import * as responses from "./response";
declare const Breaker: any;
export declare enum GenerativeAiInferenceApiKeys {
}
/**
 * This service client uses {@link common.CircuitBreaker.DefaultConfiguration} for all the operations by default if no circuit breaker configuration is defined by the user.
 */
export declare class GenerativeAiInferenceClient {
    protected static serviceEndpointTemplate: string;
    protected static endpointServiceName: string;
    protected "_realmSpecificEndpointTemplateEnabled": boolean | undefined;
    protected "_endpoint": string;
    protected "_defaultHeaders": any;
    protected "_clientConfiguration": common.ClientConfiguration;
    protected _circuitBreaker: typeof Breaker | null;
    protected _httpOptions: any;
    protected _bodyDuplexMode: any;
    targetService: string;
    protected _regionId: string;
    protected "_region": common.Region;
    protected _lastSetRegionOrRegionId: string;
    protected _httpClient: common.HttpClient;
    protected _authProvider: common.AuthenticationDetailsProvider | undefined;
    constructor(params: common.AuthParams, clientConfiguration?: common.ClientConfiguration);
    /**
     * Get the endpoint that is being used to call (ex, https://www.example.com).
     */
    get endpoint(): string;
    /**
     * Sets the endpoint to call (ex, https://www.example.com).
     * @param endpoint The endpoint of the service.
     */
    set endpoint(endpoint: string);
    get logger(): import("oci-common/lib/log").Logger;
    /**
     * Determines whether realm specific endpoint should be used or not.
     * Set realmSpecificEndpointTemplateEnabled to "true" if the user wants to enable use of realm specific endpoint template, otherwise set it to "false"
     * @param realmSpecificEndpointTemplateEnabled flag to enable the use of realm specific endpoint template
     */
    set useRealmSpecificEndpointTemplate(realmSpecificEndpointTemplateEnabled: boolean);
    /**
     * Sets the region to call (ex, Region.US_PHOENIX_1).
     * Note, this will call {@link #endpoint(String) endpoint} after resolving the endpoint.
     * @param region The region of the service.
     */
    set region(region: common.Region);
    /**
     * Sets the regionId to call (ex, 'us-phoenix-1').
     *
     * Note, this will first try to map the region ID to a known Region and call {@link #region(Region) region}.
     * If no known Region could be determined, it will create an endpoint assuming its in default Realm OC1
     * and then call {@link #endpoint(String) endpoint}.
     * @param regionId The public region ID.
     */
    set regionId(regionId: string);
    /**
     * Shutdown the circuit breaker used by the client when it is no longer needed
     */
    shutdownCircuitBreaker(): void;
    /**
     * Close the provider if possible which in turn shuts down any associated circuit breaker
     */
    closeProvider(): void;
    /**
     * Close the client once it is no longer needed
     */
    close(): void;
    /**
     * Applies guardrails to the input text, including content moderation, PII detection, and prompt injection protection.
     *
     * This operation uses {@link common.OciSdkDefaultRetryConfiguration} by default if no retry configuration is defined by the user.
     * @param ApplyGuardrailsRequest
     * @return ApplyGuardrailsResponse
     * @throws OciError when an error occurs
     * @example Click {@link https://docs.oracle.com/en-us/iaas/tools/typescript-sdk-examples/latest/generativeaiinference/ApplyGuardrails.ts.html |here} to see how to use ApplyGuardrails API.
     */
    applyGuardrails(applyGuardrailsRequest: requests.ApplyGuardrailsRequest): Promise<responses.ApplyGuardrailsResponse>;
    /**
     * Creates a response for the given conversation.
     *
     * This operation uses {@link common.OciSdkDefaultRetryConfiguration} by default if no retry configuration is defined by the user.
     * @param ChatRequest
     * @return ChatResponse
     * @throws OciError when an error occurs
     * @example Click {@link https://docs.oracle.com/en-us/iaas/tools/typescript-sdk-examples/latest/generativeaiinference/Chat.ts.html |here} to see how to use Chat API.
     */
    chat(chatRequest: requests.ChatRequest): Promise<responses.ChatResponse | ReadableStream<Uint8Array> | null>;
    /**
       * Produces embeddings for the inputs.
  * <p>
  An embedding is numeric representation of a piece of text. This text can be a phrase, a sentence, or one or more paragraphs. The Generative AI embedding model transforms each phrase, sentence, or paragraph that you input, into an array with 1024 numbers. You can use these embeddings for finding similarity in your input text such as finding phrases that are similar in context or category. Embeddings are mostly used for semantic searches where the search function focuses on the meaning of the text that it's searching through rather than finding results based on keywords.
  *
       * This operation uses {@link common.OciSdkDefaultRetryConfiguration} by default if no retry configuration is defined by the user.
       * @param EmbedTextRequest
       * @return EmbedTextResponse
       * @throws OciError when an error occurs
       * @example Click {@link https://docs.oracle.com/en-us/iaas/tools/typescript-sdk-examples/latest/generativeaiinference/EmbedText.ts.html |here} to see how to use EmbedText API.
       */
    embedText(embedTextRequest: requests.EmbedTextRequest): Promise<responses.EmbedTextResponse>;
    /**
     * Generates a text response based on the user prompt.
     *
     * This operation uses {@link common.OciSdkDefaultRetryConfiguration} by default if no retry configuration is defined by the user.
     * @param GenerateTextRequest
     * @return GenerateTextResponse
     * @throws OciError when an error occurs
     * @example Click {@link https://docs.oracle.com/en-us/iaas/tools/typescript-sdk-examples/latest/generativeaiinference/GenerateText.ts.html |here} to see how to use GenerateText API.
     */
    generateText(generateTextRequest: requests.GenerateTextRequest): Promise<responses.GenerateTextResponse | ReadableStream<Uint8Array> | null>;
    /**
       * Reranks the text responses based on the input documents and a prompt.
  * <p>
  Rerank assigns an index and a relevance score to each document, indicating which document is most related to the prompt.
  *
       * This operation uses {@link common.OciSdkDefaultRetryConfiguration} by default if no retry configuration is defined by the user.
       * @param RerankTextRequest
       * @return RerankTextResponse
       * @throws OciError when an error occurs
       * @example Click {@link https://docs.oracle.com/en-us/iaas/tools/typescript-sdk-examples/latest/generativeaiinference/RerankText.ts.html |here} to see how to use RerankText API.
       */
    rerankText(rerankTextRequest: requests.RerankTextRequest): Promise<responses.RerankTextResponse>;
    /**
     * Summarizes the input text.
     *
     * This operation uses {@link common.OciSdkDefaultRetryConfiguration} by default if no retry configuration is defined by the user.
     * @param SummarizeTextRequest
     * @return SummarizeTextResponse
     * @throws OciError when an error occurs
     * @example Click {@link https://docs.oracle.com/en-us/iaas/tools/typescript-sdk-examples/latest/generativeaiinference/SummarizeText.ts.html |here} to see how to use SummarizeText API.
     */
    summarizeText(summarizeTextRequest: requests.SummarizeTextRequest): Promise<responses.SummarizeTextResponse>;
}
export {};
