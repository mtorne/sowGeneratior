"use strict";
/**
 * Generative AI Service Inference API
 * OCI Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases for text generation, summarization, and text embeddings.

Use the Generative AI service inference API to access your custom model endpoints, or to try the out-of-the-box models to {@link #eNGenerative-ai-inferenceLatestChatResultChat(ENGenerative-ai-inferenceLatestChatResultChatRequest) eNGenerative-ai-inferenceLatestChatResultChat}, {@link #eNGenerative-ai-inferenceLatestGenerateTextResultGenerateText(ENGenerative-ai-inferenceLatestGenerateTextResultGenerateTextRequest) eNGenerative-ai-inferenceLatestGenerateTextResultGenerateText}, {@link #eNGenerative-ai-inferenceLatestSummarizeTextResultSummarizeText(ENGenerative-ai-inferenceLatestSummarizeTextResultSummarizeTextRequest) eNGenerative-ai-inferenceLatestSummarizeTextResultSummarizeText}, and {@link #eNGenerative-ai-inferenceLatestEmbedTextResultEmbedText(ENGenerative-ai-inferenceLatestEmbedTextResultEmbedTextRequest) eNGenerative-ai-inferenceLatestEmbedTextResultEmbedText}.

To use a Generative AI custom model for inference, you must first create an endpoint for that model. Use the {@link #eNGenerative-aiLatest(ENGenerative-aiLatestRequest) eNGenerative-aiLatest} to {@link #eNGenerative-aiLatestModel(ENGenerative-aiLatestModelRequest) eNGenerative-aiLatestModel} by fine-tuning an out-of-the-box model, or a previous version of a custom model, using your own data. Fine-tune the custom model on a {@link #eNGenerative-aiLatestDedicatedAiCluster(ENGenerative-aiLatestDedicatedAiClusterRequest) eNGenerative-aiLatestDedicatedAiCluster}. Then, create a {@link #eNGenerative-aiLatestDedicatedAiCluster(ENGenerative-aiLatestDedicatedAiClusterRequest) eNGenerative-aiLatestDedicatedAiCluster} with an {@link Endpoint} to host your custom model. For resource management in the Generative AI service, use the {@link #eNGenerative-aiLatest(ENGenerative-aiLatestRequest) eNGenerative-aiLatest}.

To learn more about the service, see the [Generative AI documentation](https://docs.oracle.com/iaas/Content/generative-ai/home.htm).

 * OpenAPI spec version: 20231130
 *
 *
 * NOTE: This class is auto generated by OracleSDKGenerator.
 * Do not edit the class manually.
 *
 * Copyright (c) 2020, 2025, Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.CohereChatRequest = void 0;
const model = __importStar(require("../model"));
var CohereChatRequest;
(function (CohereChatRequest) {
    let PromptTruncation;
    (function (PromptTruncation) {
        PromptTruncation["Off"] = "OFF";
        PromptTruncation["AutoPreserveOrder"] = "AUTO_PRESERVE_ORDER";
    })(PromptTruncation = CohereChatRequest.PromptTruncation || (CohereChatRequest.PromptTruncation = {}));
    let CitationQuality;
    (function (CitationQuality) {
        CitationQuality["Accurate"] = "ACCURATE";
        CitationQuality["Fast"] = "FAST";
    })(CitationQuality = CohereChatRequest.CitationQuality || (CohereChatRequest.CitationQuality = {}));
    let SafetyMode;
    (function (SafetyMode) {
        SafetyMode["Contextual"] = "CONTEXTUAL";
        SafetyMode["Strict"] = "STRICT";
        SafetyMode["Off"] = "OFF";
    })(SafetyMode = CohereChatRequest.SafetyMode || (CohereChatRequest.SafetyMode = {}));
    function getJsonObj(obj, isParentJsonObj) {
        const jsonObj = Object.assign(Object.assign({}, (isParentJsonObj ? obj : model.BaseChatRequest.getJsonObj(obj))), {
            "chatHistory": obj.chatHistory
                ? obj.chatHistory.map(item => {
                    return model.CohereMessage.getJsonObj(item);
                })
                : undefined,
            "responseFormat": obj.responseFormat
                ? model.CohereResponseFormat.getJsonObj(obj.responseFormat)
                : undefined,
            "streamOptions": obj.streamOptions
                ? model.StreamOptions.getJsonObj(obj.streamOptions)
                : undefined,
            "tools": obj.tools
                ? obj.tools.map(item => {
                    return model.CohereTool.getJsonObj(item);
                })
                : undefined,
            "toolResults": obj.toolResults
                ? obj.toolResults.map(item => {
                    return model.CohereToolResult.getJsonObj(item);
                })
                : undefined
        });
        return jsonObj;
    }
    CohereChatRequest.getJsonObj = getJsonObj;
    CohereChatRequest.apiFormat = "COHERE";
    function getDeserializedJsonObj(obj, isParentJsonObj) {
        const jsonObj = Object.assign(Object.assign({}, (isParentJsonObj
            ? obj
            : model.BaseChatRequest.getDeserializedJsonObj(obj))), {
            "chatHistory": obj.chatHistory
                ? obj.chatHistory.map(item => {
                    return model.CohereMessage.getDeserializedJsonObj(item);
                })
                : undefined,
            "responseFormat": obj.responseFormat
                ? model.CohereResponseFormat.getDeserializedJsonObj(obj.responseFormat)
                : undefined,
            "streamOptions": obj.streamOptions
                ? model.StreamOptions.getDeserializedJsonObj(obj.streamOptions)
                : undefined,
            "tools": obj.tools
                ? obj.tools.map(item => {
                    return model.CohereTool.getDeserializedJsonObj(item);
                })
                : undefined,
            "toolResults": obj.toolResults
                ? obj.toolResults.map(item => {
                    return model.CohereToolResult.getDeserializedJsonObj(item);
                })
                : undefined
        });
        return jsonObj;
    }
    CohereChatRequest.getDeserializedJsonObj = getDeserializedJsonObj;
})(CohereChatRequest = exports.CohereChatRequest || (exports.CohereChatRequest = {}));
//# sourceMappingURL=cohere-chat-request.js.map