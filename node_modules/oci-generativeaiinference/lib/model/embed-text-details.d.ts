/**
 * Generative AI Service Inference API
 * OCI Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases for text generation, summarization, and text embeddings.

Use the Generative AI service inference API to access your custom model endpoints, or to try the out-of-the-box models to {@link #eNGenerative-ai-inferenceLatestChatResultChat(ENGenerative-ai-inferenceLatestChatResultChatRequest) eNGenerative-ai-inferenceLatestChatResultChat}, {@link #eNGenerative-ai-inferenceLatestGenerateTextResultGenerateText(ENGenerative-ai-inferenceLatestGenerateTextResultGenerateTextRequest) eNGenerative-ai-inferenceLatestGenerateTextResultGenerateText}, {@link #eNGenerative-ai-inferenceLatestSummarizeTextResultSummarizeText(ENGenerative-ai-inferenceLatestSummarizeTextResultSummarizeTextRequest) eNGenerative-ai-inferenceLatestSummarizeTextResultSummarizeText}, and {@link #eNGenerative-ai-inferenceLatestEmbedTextResultEmbedText(ENGenerative-ai-inferenceLatestEmbedTextResultEmbedTextRequest) eNGenerative-ai-inferenceLatestEmbedTextResultEmbedText}.

To use a Generative AI custom model for inference, you must first create an endpoint for that model. Use the {@link #eNGenerative-aiLatest(ENGenerative-aiLatestRequest) eNGenerative-aiLatest} to {@link #eNGenerative-aiLatestModel(ENGenerative-aiLatestModelRequest) eNGenerative-aiLatestModel} by fine-tuning an out-of-the-box model, or a previous version of a custom model, using your own data. Fine-tune the custom model on a {@link #eNGenerative-aiLatestDedicatedAiCluster(ENGenerative-aiLatestDedicatedAiClusterRequest) eNGenerative-aiLatestDedicatedAiCluster}. Then, create a {@link #eNGenerative-aiLatestDedicatedAiCluster(ENGenerative-aiLatestDedicatedAiClusterRequest) eNGenerative-aiLatestDedicatedAiCluster} with an {@link Endpoint} to host your custom model. For resource management in the Generative AI service, use the {@link #eNGenerative-aiLatest(ENGenerative-aiLatestRequest) eNGenerative-aiLatest}.

To learn more about the service, see the [Generative AI documentation](https://docs.oracle.com/iaas/Content/generative-ai/home.htm).

 * OpenAPI spec version: 20231130
 *
 *
 * NOTE: This class is auto generated by OracleSDKGenerator.
 * Do not edit the class manually.
 *
 * Copyright (c) 2020, 2025, Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */
import * as model from "../model";
/**
 * Details for the request to embed texts.
 */
export interface EmbedTextDetails {
    /**
     * Provide a list of strings or one base64 encoded image with {@code input_type} setting to {@code IMAGE}. If text embedding, each string can be words, a phrase, or a paragraph. The maximum length of each string entry in the list is 512 tokens.
     */
    "inputs": Array<string>;
    "servingMode": model.DedicatedServingMode | model.OnDemandServingMode;
    /**
     * The OCID of compartment in which to call the Generative AI service to create text embeddings.
     */
    "compartmentId": string;
    /**
     * Whether or not to include the original inputs in the response. Results are index-based.
     */
    "isEcho"?: boolean;
    /**
     * For an input that's longer than the maximum token length, specifies which part of the input text will be truncated.
     */
    "truncate"?: EmbedTextDetails.Truncate;
    /**
     * Specifies the input type.
     */
    "inputType"?: EmbedTextDetails.InputType;
}
export declare namespace EmbedTextDetails {
    enum Truncate {
        None = "NONE",
        Start = "START",
        End = "END"
    }
    enum InputType {
        SearchDocument = "SEARCH_DOCUMENT",
        SearchQuery = "SEARCH_QUERY",
        Classification = "CLASSIFICATION",
        Clustering = "CLUSTERING",
        Image = "IMAGE"
    }
    function getJsonObj(obj: EmbedTextDetails): object;
    function getDeserializedJsonObj(obj: EmbedTextDetails): object;
}
