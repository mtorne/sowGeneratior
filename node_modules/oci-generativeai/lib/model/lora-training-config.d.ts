/**
 * Generative AI Service Management API
 * OCI Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases for text generation, summarization, and text embeddings.

Use the Generative AI service management API to create and manage {@link DedicatedAiCluster}, {@link Endpoint}, {@link Model}, and {@link WorkRequest} in the Generative AI service. For example, create a custom model by fine-tuning an out-of-the-box model using your own data, on a fine-tuning dedicated AI cluster. Then, create a hosting dedicated AI cluster with an endpoint to host your custom model.

To access your custom model endpoints, or to try the out-of-the-box models to generate text, summarize, and create text embeddings see the [Generative AI Inference API](https://docs.oracle.com/iaas/api/#/en/generative-ai-inference/latest/).

To learn more about the service, see the [Generative AI documentation](https://docs.oracle.com/iaas/Content/generative-ai/home.htm).

 * OpenAPI spec version: 20231130
 *
 *
 * NOTE: This class is auto generated by OracleSDKGenerator.
 * Do not edit the class manually.
 *
 * Copyright (c) 2020, 2025, Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */
import * as model from "../model";
/**
 * The Lora training method hyperparameters.
 *
 */
export interface LoraTrainingConfig extends model.TrainingConfig {
    /**
     * This parameter represents the LoRA rank of the update matrices. Note: Numbers greater than Number.MAX_SAFE_INTEGER will result in rounding issues.
     */
    "loraR"?: number;
    /**
     * This parameter represents the scaling factor for the weight matrices in LoRA. Note: Numbers greater than Number.MAX_SAFE_INTEGER will result in rounding issues.
     */
    "loraAlpha"?: number;
    /**
     * This parameter indicates the dropout probability for LoRA layers. Note: Numbers greater than Number.MAX_SAFE_INTEGER will result in rounding issues.
     */
    "loraDropout"?: number;
    "trainingConfigType": string;
}
export declare namespace LoraTrainingConfig {
    function getJsonObj(obj: LoraTrainingConfig, isParentJsonObj?: boolean): object;
    const trainingConfigType = "LORA_TRAINING_CONFIG";
    function getDeserializedJsonObj(obj: LoraTrainingConfig, isParentJsonObj?: boolean): object;
}
